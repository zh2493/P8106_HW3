---
title: "HW3"
author: "ZiqianHe"
date: "3/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(caret)
library(glmnet)
library(mlbench)
library(pROC)
library(AppliedPredictiveModeling)
library(MASS)
library(tidyverse)
library(vip)
library(pdp)

```


##a
```{r}
auto = read.csv("D:/columbia/term2/ds2/hw3/auto.csv") %>% 
  na.omit() %>% 
  mutate(mpg_cat = as.factor(mpg_cat),
         mpg_cat = fct_relevel(mpg_cat, c("low", "high")))
  
set.seed(2022)
#The data is divided into two parts (training and test). 
rowTrain <- createDataPartition(y = auto$mpg_cat,
                                p = 0.7,
                                list = FALSE)

test <- auto[-rowTrain, ]
# training data
x <- model.matrix(mpg_cat~.,auto)[rowTrain]
y <- auto$mpg_cat[rowTrain]

# test data
x2 <- model.matrix(mpg_cat~.,auto)[-rowTrain]
y2 <- auto$mpg_cat[-rowTrain]
```


##a Produce some graphical or numerical summaries of the data.
```{r}
summary(auto)
theme1 <- transparentTheme(trans = .4)
trellis.par.set(theme1)

#plot of continuous variables
featurePlot(x = auto[, 1:7], 
            y = auto$mpg_cat,
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))

#plot of categorical variables
auto %>% 
    mutate(
    origin = case_when(origin == "1" ~ "American",
                       origin == "2" ~ "European",
                       origin == "3" ~ "Japanese"),
    origin = as.factor(origin),
    mpg_cat = as.factor(mpg_cat),
    mpg_cat = fct_relevel(mpg_cat, "low")
  ) %>%
  dplyr::select(-displacement, -horsepower, -weight, -acceleration) %>% 
  ggplot(aes(x = origin, fill = mpg_cat)) + 
  geom_bar(position = "fill") +
  labs(x = "Origin",
       y = "Porpotion of Gas mileage")
```
We have 7 predictors. the response is mpg_cat. 


##b Perform a logistic regression using the training data
```{r}
# Logistic regression
data2 <-
  auto %>% 
  mutate(year = as.factor(year),
         origin = as.factor(origin))
set.seed(2)
rowTrain2 <- createDataPartition(y = data2$mpg_cat,
                                p = 0.7,
                                list = FALSE)

glm.fit <- glm(mpg_cat ~ ., 
               data = data2, 
               subset = rowTrain2, 
               family = binomial(link = "logit"))

summary(glm.fit)
```
predictors of `weight`, `year73`, `year79-82` and `origin2`are statistically significant.


* Compute the confusion matrix and overall fraction of correct predictions using the test data
```{r}
#check on the test data
test.pred.prob <- predict(glm.fit, newdata = data2[-rowTrain2,],
                           type = "response")
test.pred <- rep("low", length(test.pred.prob))
test.pred[test.pred.prob>0.5] <- "high"

confusionMatrix(data = as.factor(test.pred),
                reference = data2$mpg_cat[-rowTrain2],
                positive = "high")
```
Our confusion matrix shows that, overall fraction of correct predictions, is (55 + 52)/(55 + 3 + 6 + 52)  = 0.9224 (95% CI: 0.8578, 0.9639) . 
The confusion matrix also tells us that our no information rate is 50%, which means that if we had no information and made the same class prediction for all observations, our model would be 50% accurate, which is not very ideal. 
p-value <2e-16 the accuracy is statistically significantly better than no information rate. 
Sensitivity : 0.8966, Specificity : 0.9483 , with a positive predictive value of 0.9455 and a negative predictive value of 0.9016.Balanced Accuracy : 0.9224. 

##c Train a multivariate adaptive regression spline (MARS) model
```{r}
set.seed(1)
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

model.mars <- train(x = auto[rowTrain,1:7],
                    y = auto$mpg_cat[rowTrain],
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:4, 
                                           nprune = 2:20),
                    metric = "ROC",
                    trControl = ctrl)
summary(model.mars)
plot(model.mars)

model.mars$bestTune
coef(model.mars$finalModel) 
```
Earth selected 9 of 19 terms, and 5 of 7 predictors, RSq= 0.859118

##d Perform LDA, Plot the linear discriminants in LDA
```{r}
lda.fit <- lda(mpg_cat~., data = auto,
               subset = rowTrain)
plot(lda.fit)

lda.fit$scaling

```
two classes, so we have k = 2-1 = 1 linear discriminants.


Using caret:
```{r}
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

set.seed(11)
model.lda <- train(x = auto[rowTrain,1:7],
                   y = auto$mpg_cat[rowTrain],
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

model.lda$results

```
the ROC is 0.9588957, Sensitive 0.846044 and Specificity 0.9710989

##e model comparison, Plot its ROC curve using the test data. Report the AUC and the misclassification error rate.
```{r}
logit_caret = train(x = rowTrain,
                        y = y,
                        method = "glm",
                        metric = "ROC",
                        trControl = ctrl)

res = resamples(list(Logit = logit_caret , 
                           MARS = model.mars,
                           LDA = model.lda))

summary(res)
bwplot(res, metric = "ROC")
```
through the resampling, the mars has the highest ROC.

```{r}
# plot ROC curv, prediction 
mars_pred <- predict(model.mars, newdata = auto[-rowTrain, 1:7], type = "prob")[,2]
roc_mars <- roc(auto$mpg_cat[-rowTrain], mars_pred)

#AUC and misclassification error rate
auc_mars = roc_mars$auc[1]
auc_mars

test_pred = rep("low", length(mars_pred))
test_pred[mars_pred > 0.5] = "high"
confusionMatrix(data = as.factor(test_pred),
                reference = auto$mpg_cat[-rowTrain],
                positive = "high")

plot(roc_mars, legacy.axis = TRUE)
```
above shoews the ROC curve, the AUC 0.9497622. the mars model has a misclassification rate of 1 - 0.9497622




